{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dd4e17-f047-473a-acb6-4bc495b05bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Downloading econml-0.16.0-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (2.1.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (1.6.1)\n",
      "Collecting sparse (from econml)\n",
      "  Downloading sparse-0.17.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (1.4.2)\n",
      "Requirement already satisfied: statsmodels>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (0.14.4)\n",
      "Requirement already satisfied: pandas>1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (2.2.3)\n",
      "Collecting shap<0.49.0,>=0.38.1 (from econml)\n",
      "  Downloading shap-0.48.0-cp313-cp313-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (4.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from econml) (24.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn<1.7,>=1.0->econml) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from shap<0.49.0,>=0.38.1->econml) (4.67.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from shap<0.49.0,>=0.38.1->econml) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from shap<0.49.0,>=0.38.1->econml) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\asus\\anaconda3\\lib\\site-packages (from shap<0.49.0,>=0.38.1->econml) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from shap<0.49.0,>=0.38.1->econml) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from numba>=0.54->shap<0.49.0,>=0.38.1->econml) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>1.0->econml) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>1.0->econml) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas>1.0->econml) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>1.0->econml) (1.17.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from statsmodels>=0.10->econml) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap<0.49.0,>=0.38.1->econml) (0.4.6)\n",
      "Downloading econml-0.16.0-cp313-cp313-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 684.7 kB/s eta 0:00:03\n",
      "   ------------- -------------------------- 0.8/2.3 MB 788.8 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.3 MB 788.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.3 MB 770.0 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.3 MB 770.0 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 791.8 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.6/2.3 MB 801.2 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 801.2 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 801.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 719.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.1/2.3 MB 526.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 529.4 kB/s eta 0:00:00\n",
      "Downloading shap-0.48.0-cp313-cp313-win_amd64.whl (545 kB)\n",
      "   ---------------------------------------- 0.0/545.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/545.1 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/545.1 kB ? eta -:--:--\n",
      "   -------------------------------------- - 524.3/545.1 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- 545.1/545.1 kB 878.7 kB/s eta 0:00:00\n",
      "Downloading sparse-0.17.0-py2.py3-none-any.whl (259 kB)\n",
      "Installing collected packages: sparse, shap, econml\n",
      "\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "  Attempting uninstall: shap\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "    Found existing installation: shap 0.50.0\n",
      "   ---------------------------------------- 0/3 [sparse]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "    Uninstalling shap-0.50.0:\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "      Successfully uninstalled shap-0.50.0\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   ------------- -------------------------- 1/3 [shap]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   -------------------------- ------------- 2/3 [econml]\n",
      "   ---------------------------------------- 3/3 [econml]\n",
      "\n",
      "Successfully installed econml-0.16.0 shap-0.48.0 sparse-0.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\pip-uninstall-1_oflkzy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\~hap'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a650a4c-dda3-49c2-844d-0b41296c6e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from econml.dml import DML\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9425b97-8405-4940-a08b-bd2ffbcbec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE: 2.854488934404438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\econml\\dml\\dml.py:192: UserWarning: The final model has a nonzero intercept for at least one outcome; it will be subtracted, but consider fitting a model without an intercept if possible.\n",
      "  warn(\"The final model has a nonzero intercept for at least one outcome; \"\n"
     ]
    }
   ],
   "source": [
    "from econml.dml import DML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Generate synthetic dataset\n",
    "# -----------------------------------------------------\n",
    "np.random.seed(42)\n",
    "n = 2000\n",
    "\n",
    "X = np.random.normal(0, 1, size=(n, 5))\n",
    "T = (X[:, 0] + X[:, 1] + np.random.randn(n) > 0).astype(int)  # binary treatment\n",
    "Y = 3*T + X[:, 2] + np.random.randn(n)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Models for nuisance (BOTH must be regressors)\n",
    "# -----------------------------------------------------\n",
    "model_y = RandomForestRegressor()\n",
    "model_t = RandomForestRegressor()      # IMPORTANT: changed to regressor\n",
    "\n",
    "# final stage model\n",
    "model_final = LinearRegression()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. DML estimator\n",
    "# -----------------------------------------------------\n",
    "dml = DML(\n",
    "    model_y=model_y,\n",
    "    model_t=model_t,\n",
    "    model_final=model_final,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. FIT â€” use keyword arguments\n",
    "# -----------------------------------------------------\n",
    "dml.fit(Y=Y, T=T, X=X)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. ATE\n",
    "# -----------------------------------------------------\n",
    "ate = dml.ate(X)\n",
    "print(\"Estimated ATE:\", ate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2a452b-62b6-4f18-8e59-e3f254bdfc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dataset n=5000, p=60, mean(T)=0.485\n",
      "Cross-fitting finished in 114.4s\n",
      "Out-of-fold propensity AUC: 0.6850\n",
      "mean(rY): -5.6734e-03, mean(rT): 3.7913e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11864\\3267418842.py:210: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cate_by_bin = df.groupby('X0_q').apply(cate_bin).rename('cate_est')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- RESULTS ----\n",
      "DML ATE: 1.1939 SE: 0.0346 95% CI (HC1): (1.126, 1.2618)\n",
      "Bootstrap 95% CI: (np.float64(1.1255), np.float64(1.2776))\n",
      "Naive OLS ATE: 1.5745 95% CI: (1.4729, 1.6761)\n",
      "OLS with controls ATE: 1.5517 95% CI: (1.4485, 1.6549)\n",
      "True sample average tau: 1.1664\n",
      "\n",
      "CATE by X0 quintile:\n",
      " X0_q\n",
      "0    0.838773\n",
      "1    1.056887\n",
      "2    1.233849\n",
      "3    1.201069\n",
      "4    1.608024\n",
      "\n",
      "Saved summary CSVs and PNGs with prefix: dml_run_*\n",
      "\n",
      "All outputs saved. Submit the results CSVs and PNGs to Cultus for best marks.\n"
     ]
    }
   ],
   "source": [
    "# dml_pipeline_synthetic_improved.py\n",
    "# Run with: python dml_pipeline_synthetic_improved.py\n",
    "# Requires: numpy, pandas, scikit-learn, statsmodels, matplotlib, seaborn\n",
    "# pip install numpy pandas scikit-learn statsmodels matplotlib seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---------- SETTINGS ----------\n",
    "n = 5000           # sample size (reduce if needed)\n",
    "p = 60             # number of features (>=50)\n",
    "K = 5              # cross-fitting folds\n",
    "noise_scale = 1.0\n",
    "n_estimators = 80\n",
    "max_depth = 4\n",
    "BOOTSTRAP_B = 500   # bootstrap iterations for CI\n",
    "SAVE_PREFIX = \"dml_run\"\n",
    "# ------------------------------\n",
    "\n",
    "# ----------------\n",
    "# 1) Synthetic data generation (complex non-linear relationships)\n",
    "# ----------------\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.random.normal(size=(n, p))\n",
    "propensity_score = (\n",
    "    0.8 * np.tanh(X[:, 0] * 1.2 + X[:, 1]**2 - 0.5 * X[:, 2]) +\n",
    "    0.6 * np.sin(0.5 * X[:, 3] * X[:, 4]) +\n",
    "    0.4 * (X[:, 5] * X[:, 6]) +\n",
    "    0.3 * (X[:, 7]**3) +\n",
    "    0.2 * np.sum(X[:, 8:12] * np.linspace(0.1, 0.4, 4), axis=1)\n",
    ")\n",
    "propensity = sigmoid(propensity_score - np.median(propensity_score))\n",
    "propensity = np.clip(propensity, 0.02, 0.98)\n",
    "T = np.random.binomial(1, propensity, size=n)\n",
    "\n",
    "true_tau = 2.0 * sigmoid(0.6 * X[:, 0] + 0.4 * X[:, 1]**2 - 0.3 * X[:, 2])\n",
    "\n",
    "mu_X = (\n",
    "    1.5 * np.cos(X[:, 0]) +\n",
    "    0.8 * (X[:, 1]**2) -\n",
    "    0.6 * np.tanh(X[:, 2] * X[:, 3]) +\n",
    "    0.5 * X[:, 4] +\n",
    "    0.3 * X[:, 5] * X[:, 6] +\n",
    "    0.2 * np.sum(X[:, 10:18] * np.linspace(0.05, 0.2, 8), axis=1)\n",
    ")\n",
    "\n",
    "Y = mu_X + T * true_tau + np.random.normal(scale=noise_scale, size=n)\n",
    "\n",
    "colnames = [f\"X{i}\" for i in range(p)]\n",
    "df = pd.DataFrame(X, columns=colnames)\n",
    "df['T'] = T\n",
    "df['Y'] = Y\n",
    "df['propensity_true'] = propensity\n",
    "df['tau_true'] = true_tau\n",
    "\n",
    "print(f\"Generated dataset n={n}, p={p}, mean(T)={T.mean():.3f}\")\n",
    "\n",
    "# ----------------\n",
    "# 2) Quick EDA / checks (positivity & overlap)\n",
    "# ----------------\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['propensity_true'], bins=40, kde=False)\n",
    "plt.title(\"True propensity score distribution\")\n",
    "plt.xlabel(\"propensity_true\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_propensity_true_hist.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ----------------\n",
    "# 3) Cross-fitting to get out-of-fold nuisance predictions\n",
    "# ----------------\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "m_hat = np.zeros(n)   # E[Y|X]\n",
    "g_hat = np.zeros(n)   # E[T|X] (propensity)\n",
    "model_m_importances = []\n",
    "model_g_importances = []\n",
    "\n",
    "start = time.time()\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df), 1):\n",
    "    X_train = df.iloc[train_idx][colnames].values\n",
    "    X_test = df.iloc[test_idx][colnames].values\n",
    "    Y_train = df.iloc[train_idx]['Y'].values\n",
    "    T_train = df.iloc[train_idx]['T'].values\n",
    "\n",
    "    # outcome model (regressor)\n",
    "    model_m = HistGradientBoostingRegressor(max_iter=n_estimators, max_depth=max_depth, random_state=SEED+fold)\n",
    "    model_m.fit(X_train, Y_train)\n",
    "    m_hat[test_idx] = model_m.predict(X_test)\n",
    "\n",
    "    # treatment model (classifier for propensity; we will use predict_proba)\n",
    "    model_g = HistGradientBoostingClassifier(max_iter=n_estimators, max_depth=max_depth, random_state=SEED+fold)\n",
    "    model_g.fit(X_train, T_train)\n",
    "    # predict_proba -> probability of T=1\n",
    "    g_hat[test_idx] = model_g.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # record permutation importances on test to report later (small cost)\n",
    "    try:\n",
    "        imp_m = permutation_importance(model_m, X_test, df.iloc[test_idx]['Y'].values, n_repeats=10, random_state=SEED)\n",
    "        model_m_importances.append(imp_m.importances_mean)\n",
    "    except Exception:\n",
    "        model_m_importances.append(np.zeros(len(colnames)))\n",
    "    try:\n",
    "        imp_g = permutation_importance(model_g, X_test, df.iloc[test_idx]['T'].values, n_repeats=10, random_state=SEED)\n",
    "        model_g_importances.append(imp_g.importances_mean)\n",
    "    except Exception:\n",
    "        model_g_importances.append(np.zeros(len(colnames)))\n",
    "\n",
    "print(f\"Cross-fitting finished in {time.time() - start:.1f}s\")\n",
    "\n",
    "# ----------------\n",
    "# 4) Diagnostics for nuisance fits\n",
    "# ----------------\n",
    "# Propensity calibration plot\n",
    "prob_true, prob_pred = calibration_curve(df['T'].values, g_hat, n_bins=10)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1],[0,1],'--', alpha=0.6)\n",
    "plt.xlabel(\"Predicted propensity\")\n",
    "plt.ylabel(\"Observed frequency\")\n",
    "plt.title(\"Propensity calibration (oof g_hat)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_propensity_calibration.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Propensity AUC (informative)\n",
    "try:\n",
    "    auc_oof = roc_auc_score(df['T'].values, g_hat)\n",
    "except Exception:\n",
    "    auc_oof = np.nan\n",
    "\n",
    "print(f\"Out-of-fold propensity AUC: {auc_oof:.4f}\")\n",
    "\n",
    "# ----------------\n",
    "# 5) Residuals and DML (residual-on-residual)\n",
    "# ----------------\n",
    "rY = df['Y'].values - m_hat\n",
    "rT = df['T'].values - g_hat\n",
    "\n",
    "# check mean residuals ~ 0\n",
    "print(f\"mean(rY): {rY.mean():.4e}, mean(rT): {rT.mean():.4e}\")\n",
    "\n",
    "# OLS of rY on rT (no intercept) with robust HC1 SEs\n",
    "ols_model = sm.OLS(rY, rT.reshape(-1, 1)).fit(cov_type='HC1')\n",
    "ate_dml = float(ols_model.params[0])\n",
    "se_dml = float(ols_model.bse[0])\n",
    "ci_dml = (ate_dml - 1.96 * se_dml, ate_dml + 1.96 * se_dml)\n",
    "\n",
    "# ----------------\n",
    "# 6) Naive OLS benchmark (Y ~ T only)\n",
    "# ----------------\n",
    "naive = sm.OLS(df['Y'].values, sm.add_constant(df['T'].values)).fit(cov_type='HC1')\n",
    "ate_naive = float(naive.params[1])\n",
    "se_naive = float(naive.bse[1])\n",
    "ci_naive = (ate_naive - 1.96*se_naive, ate_naive + 1.96*se_naive)\n",
    "\n",
    "# ----------------\n",
    "# 7) OLS with simple parametric controls (illustrative)\n",
    "# ----------------\n",
    "X_for_ols = df[['T'] + colnames[:8]].copy()\n",
    "X_for_ols = sm.add_constant(X_for_ols)\n",
    "ols_ctrl = sm.OLS(df['Y'].values, X_for_ols).fit(cov_type='HC1')\n",
    "ate_ols_ctrl = float(ols_ctrl.params['T'])\n",
    "se_ols_ctrl = float(ols_ctrl.bse['T'])\n",
    "ci_ols_ctrl = (ate_ols_ctrl - 1.96*se_ols_ctrl, ate_ols_ctrl + 1.96*se_ols_ctrl)\n",
    "\n",
    "# ----------------\n",
    "# 8) Bootstrap ATE CI (resample units, keep X,T,Y together)\n",
    "# ----------------\n",
    "rng = np.random.RandomState(SEED)\n",
    "boot_ates = []\n",
    "for b in range(BOOTSTRAP_B):\n",
    "    idx = rng.randint(0, n, n)\n",
    "    # use cross-fitted rY and rT (we treat them as fixed oof estimates)\n",
    "    rY_b = rY[idx]\n",
    "    rT_b = rT[idx]\n",
    "    try:\n",
    "        res_b = sm.OLS(rY_b, rT_b.reshape(-1,1)).fit(cov_type='HC1')\n",
    "        boot_ates.append(float(res_b.params[0]))\n",
    "    except Exception:\n",
    "        continue\n",
    "boot_ates = np.array(boot_ates)\n",
    "if len(boot_ates) > 0:\n",
    "    ci_boot = (np.percentile(boot_ates, 2.5), np.percentile(boot_ates, 97.5))\n",
    "else:\n",
    "    ci_boot = (np.nan, np.nan)\n",
    "\n",
    "# ----------------\n",
    "# 9) Quick CATE summary by X0 quintile\n",
    "# ----------------\n",
    "df['rY'] = rY\n",
    "df['rT'] = rT\n",
    "df['X0_q'] = pd.qcut(df['X0'], 5, labels=False)\n",
    "def cate_bin(g):\n",
    "    denom = (g['rT']**2).sum()\n",
    "    return (g['rY'] * g['rT']).sum() / denom if denom > 0 else np.nan\n",
    "cate_by_bin = df.groupby('X0_q').apply(cate_bin).rename('cate_est')\n",
    "\n",
    "# Also compute pointwise estimated CATE using residual-on-residual slope local approximation:\n",
    "# for simplicity here use grouping estimate above and also compute simple effect = (rY/rT) clipped\n",
    "df['cate_pointwise'] = np.where(np.abs(df['rT'])>1e-8, df['rY']/df['rT'], np.nan)\n",
    "\n",
    "# ----------------\n",
    "# 10) Important plots: CATE dist, Compare ATEs\n",
    "# ----------------\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['cate_pointwise'].dropna(), bins=50)\n",
    "plt.title(\"Pointwise CATE estimates (rY/rT)\")\n",
    "plt.xlabel(\"CATE (approx)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_cate_pointwise_hist.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "estimates = pd.Series({\n",
    "    'DML': ate_dml,\n",
    "    'Naive OLS': ate_naive,\n",
    "    'OLS w/ controls': ate_ols_ctrl,\n",
    "    'True avg tau': df['tau_true'].mean()\n",
    "})\n",
    "estimates.plot(kind='bar')\n",
    "plt.ylabel(\"ATE estimate\")\n",
    "plt.title(\"ATE estimates comparison\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_ate_comparison.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# CATE by X0 quintile plot\n",
    "plt.figure(figsize=(6,4))\n",
    "cate_by_bin.plot(marker='o')\n",
    "plt.xlabel(\"X0 quintile (0..4)\")\n",
    "plt.ylabel(\"Estimated CATE (bin)\")\n",
    "plt.title(\"CATE by X0 quintile\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_cate_by_quintile.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ----------------\n",
    "# 11) Feature importance summary (average permutation importances across folds)\n",
    "# ----------------\n",
    "mean_imp_m = np.mean(np.vstack(model_m_importances), axis=0)\n",
    "mean_imp_g = np.mean(np.vstack(model_g_importances), axis=0)\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature': colnames,\n",
    "    'imp_m': mean_imp_m,\n",
    "    'imp_g': mean_imp_g\n",
    "}).sort_values('imp_m', ascending=False)\n",
    "\n",
    "imp_df.head(12).to_csv(f\"{SAVE_PREFIX}_top_feature_importances.csv\", index=False)\n",
    "\n",
    "# save a combined importance plot for top features\n",
    "topk = 12\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='imp_m', y='feature', data=imp_df.head(topk))\n",
    "plt.title(\"Top features by permutation importance (outcome model)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PREFIX}_top_features_m.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ----------------\n",
    "# 12) Print results and save summary\n",
    "# ----------------\n",
    "print(\"---- RESULTS ----\")\n",
    "print(\"DML ATE:\", round(ate_dml, 4), \"SE:\", round(se_dml, 4), \"95% CI (HC1):\", (round(ci_dml[0],4), round(ci_dml[1],4)))\n",
    "print(\"Bootstrap 95% CI:\", (round(ci_boot[0],4), round(ci_boot[1],4)))\n",
    "print(\"Naive OLS ATE:\", round(ate_naive,4), \"95% CI:\", (round(ci_naive[0],4), round(ci_naive[1],4)))\n",
    "print(\"OLS with controls ATE:\", round(ate_ols_ctrl,4), \"95% CI:\", (round(ci_ols_ctrl[0],4), round(ci_ols_ctrl[1],4)))\n",
    "print(\"True sample average tau:\", df['tau_true'].mean().round(4))\n",
    "print(\"\\nCATE by X0 quintile:\\n\", cate_by_bin.to_string())\n",
    "print(f\"\\nSaved summary CSVs and PNGs with prefix: {SAVE_PREFIX}_*\")\n",
    "\n",
    "# Save results and sample\n",
    "df.sample(n=min(1500, n), random_state=SEED).to_csv(f'{SAVE_PREFIX}_synthetic_sample.csv', index=False)\n",
    "pd.Series({\n",
    "    'ate_dml': ate_dml,\n",
    "    'se_dml': se_dml,\n",
    "    'ci_dml_low': ci_dml[0],\n",
    "    'ci_dml_high': ci_dml[1],\n",
    "    'ci_boot_low': ci_boot[0],\n",
    "    'ci_boot_high': ci_boot[1],\n",
    "    'ate_naive': ate_naive,\n",
    "    'ate_ols_ctrl': ate_ols_ctrl,\n",
    "    'true_sample_avg_tau': df['tau_true'].mean(),\n",
    "    'propensity_auc_oof': auc_oof\n",
    "}).to_csv(f'{SAVE_PREFIX}_results_summary.csv')\n",
    "\n",
    "# Save cate_by_bin\n",
    "cate_by_bin.to_csv(f'{SAVE_PREFIX}_cate_by_quintile.csv')\n",
    "\n",
    "print(\"\\nAll outputs saved. Submit the results CSVs and PNGs to Cultus for best marks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99faa6fb-2dc5-490d-923f-525345dcc648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afffe2d-816f-41a1-b0e7-6bfeddc1af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
